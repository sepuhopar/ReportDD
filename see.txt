

\begin{document}

\studygroup{M42381}
\title{Алгоритмическая обработка СЭМ изображение с помощью машинного обучения}
\author{Меликян Сепух Каренович}{Меликян С.К.}
\supervisor{Аксенов Виталий Евгеньевич}{Аксенов В.Е.}{проф., д.т.н.}{главный научный сотрудник Университета ИТМО}
\publishyear{2023}
%% Дата выдачи задания. Можно не указывать, тогда надо будет заполнить от руки.
\startdate{01}{сентября}{2017}
%% Срок сдачи студентом работы. Можно не указывать, тогда надо будет заполнить от руки.
\finishdate{31}{мая}{2019}
%% Дата защиты. Можно не указывать, тогда надо будет заполнить от руки.
\defencedate{15}{июня}{2019}

\addconsultant{Асадулаев А.А.}

\secretary{Ильина М.С.}

%% Задание
%%% Техническое задание и исходные данные к работе
\technicalspec{Требуется разработать стилевой файл для системы \LaTeX, позволяющий оформлять бакалаврские работы и магистерские диссертации
на кафедре компьютерных технологий Университета ИТМО. Стилевой файл должен генерировать титульную страницу пояснительной записки,
задание, аннотацию и содержательную часть пояснительной записк. Первые три документа должны максимально близко соответствовать шаблонам документов,
принятым в настоящий момент на кафедре, в то время как содержательная часть должна максимально близко соответствовать ГОСТ~7.0.11-2011
на диссертацию.}

%%% Содержание выпускной квалификационной работы (перечень подлежащих разработке вопросов)
\plannedcontents{Пояснительная записка должна демонстрировать использование наиболее типичных конструкций, возникающих при составлении
пояснительной записки (перечисления, рисунки, таблицы, листинги, псевдокод), при этом должна быть составлена так, что демонстрируется
корректность работы стилевого файла. В частности, записка должна содержать не менее двух приложений (для демонстрации нумерации рисунков и таблиц
по приложениям согласно ГОСТ) и не менее десяти элементов нумерованного перечисления первого уровня вложенности (для демонстрации корректности
используемого при нумерации набора русских букв).}

%%% Исходные материалы и пособия 
\plannedsources{\begin{enumerate}
    \item ГОСТ~7.0.11-2011 <<Диссертация и автореферат диссертации>>;
    \item С.М. Львовский. Набор и верстка в системе \LaTeX;
    \item предыдущий комплект стилевых файлов, использовавшийся на кафедре компьютерных технологий.
\end{enumerate}}

%%% Цель исследования
\researchaim{Разработка удобного стилевого файла \LaTeX
             для бакалавров и магистров кафедры компьютерных технологий.}

%%% Задачи, решаемые в ВКР
\researchtargets{\begin{enumerate}
    \item обеспечение соответствия титульной страницы, задания и аннотации шаблонам, принятым в настоящее время на кафедре;
    \item обеспечение соответствия содержательной части пояснительной записки требованиям ГОСТ~7.0.11-2011 <<Диссертация и автореферат диссертации>>;
    \item обеспечение относительного удобства в использовании~--- указание данных об авторе и научном руководителе один раз и в одном месте, автоматический подсчет числа тех или иных источников.
\end{enumerate}}

%%% Использование современных пакетов компьютерных программ и технологий
\addadvancedsoftware{Пакет \texttt{tabularx} для чуть более продвинутых таблиц}{\ref{sec:tables}, Приложения~\ref{sec:app:1}, \ref{sec:app:2}}
\addadvancedsoftware{Пакет \texttt{biblatex} и программное средство \texttt{biber}}{Список использованных источников}

%%% Краткая характеристика полученных результатов 
\researchsummary{Получился, надо сказать, практически неплохой стилевик. В 2015--2018 годах
его уже использовали некоторые бакалавры и магистры. Надеюсь на продолжение.}

%%% Гранты, полученные при выполнении работы 
\researchfunding{Автор разрабатывал этот стилевик исключительно за свой счет и на
добровольных началах. Однако значительная его часть была бы невозможна, если бы
автор не написал в свое время кандидатскую диссертацию в \LaTeX,
а также не отвечал за формирование кучи научно-технических отчетов по гранту,
известному как <<5-в-100>>, что происходило при государственной финансовой поддержке
ведущих университетов Российской Федерации (субсидия 074-U01).}

%%% Наличие публикаций и выступлений на конференциях по теме выпускной работы
\researchpublications{По теме этой работы я (к счастью!) ничего не публиковал.
\begin{refsection}
Однако покажу, как можно ссылаться на свои публикации из списка литературы:
\nocite{example-english, example-russian}
\printannobibliography
\end{refsection}
}

%% Эта команда генерирует титульный лист и аннотацию.
\maketitle{Магистр}

%% Оглавление
\tableofcontents

%% Макрос для введения. Совместим со старым стилевиком.
\startprefacepage

Современное производство микроэлектроники представляет собой высокотехнологичный процесс, требующий высокой точности и контроля качества на каждом этапе. Одним из ключевых этапов в производстве микроконтроллеров является литография, которая определяет геометрию и размеры структур на полупроводниковых пластинах или вейферах. В связи с постоянным сокращением размеров транзисторов и других элементов микроконтроллеров, точность и надежность процесса литографии становятся все более важными. В этом контексте, разработка и применение эффективных методов анализа и верификации литографических процессов является одним из ключевых направлений современной науки и техники.

Одним из способов оценки качества литографических процессов является анализ контуров структур на сканирующих электронных микроскопических изображениях (СЭМ) микроконтроллеров. Выделение контуров на СЭМ-изображениях позволяет получить ценную информацию о реальных геометрических параметрах элементов микроконтроллеров, что необходимо для калибровки и верификации моделей литографического процесса, а также для количественной оценки результатов. Контурный анализ позволяет определить степень однородности площади, шаг структур по вертикали и горизонтали и другие важные параметры. Это делает его удобным инструментом для работы с полигонами, что предпочтительнее, чем анализ растровых данных, где соответствие между интенсивностью точки изображения и характеристиками поверхности исследуемого объекта может быть неочевидным.

В настоящей работе рассматриваются две модели для выделения контуров на СЭМ-изображениях микроконтроллеров: \textit{Pixel Difference Networks for Efficient Edge Detection}\cite{PidiNet} и \textit{LDC: Lightweight Dense CNN for Edge Detection}\cite{LDC}. В качестве основы для дальнейшей доработки выбрана модель LDC, которая является легковесной и эффективной для задачи выделения контуров на изображениях.

Основной целью данной работы является улучшение производительности модели LDC для выделения контуров на изображениях низкого разрешения. Это актуально, так как во многих случаях СЭМ-изображения могут быть доступны только в низком разрешении из-за ограничений оборудования или для сокращения времени сканирования и обработки данных. Однако, даже на изображениях низкого разрешения важно сохранять информацию о геометрии и расположении структур для корректной оценки литографического процесса.

Для достижения поставленной цели предполагается выполнить следующие этапы работы:

1. Изучение существующих подходов к выделению контуров на СЭМ-изображениях микроконтроллеров, включая анализ методов, основанных на глубоком обучении, и их сравнение с классическими методами, такими как операторы Собеля и Кэнни.

2. Анализ исходной архитектуры модели LDC и определение возможных направлений доработки для улучшения производительности на изображениях низкого разрешения. Возможные направления улучшения могут включать введение ансамблевое обучение, Fine-Tuning и техник аугментации данных для обучения модели.

3. Реализация предложенных улучшений и проведение экспериментов для оценки их эффективности. Сравнение результатов работы модифицированной модели LDC с результатами исходной модели и других существующих подходов.

4. Анализ полученных результатов и выработка рекомендаций по дальнейшему улучшению модели и ее применению в практических задачах анализа литографических процессов.

Ожидается, что результаты данной работы позволят повысить эффективность выделения контуров на СЭМ-изображениях микроконтроллеров низкого разрешения, что в свою очередь приведет к более точной оценке качества литографических процессов и верификации моделей процесса. Это имеет важное значение для дальнейшего развития микроэлектроники и сокращения размеров элементов микроконтроллеров, что является одним из ключевых факторов повышения производительности и энергоэффективности современных электронных устройств.

Важным аспектом данной работы является также разработка методологии для оценки качества выделения контуров на СЭМ-изображениях. В рамках работы предполагается использование существующих метрик качества, таких как Precision, Recall, F1-score и IoU (Intersection over Union), а также  OIS, ODS метрики для задач извлечения контуров и еще рассмотрение возможности разработки новых метрик, специфичных для задач анализа литографических процессов и работы с СЭМ-изображениями микроконтроллеров.

Таким образом, данная работа призвана внести свой вклад в развитие методов анализа и верификации литографических процессов на основе выделения контуров на СЭМ-изображениях микроконтроллеров. Ожидается, что результаты работы будут полезными для исследователей и инженеров, работающих в области микроэлектроники, а также для разработчиков алгоритмов компьютерного зрения и глубокого обучения, применяемых в этой области.

Результаты работы могут быть представлены в виде научных статей, публикуемых в рецензируемых журналах и материалах конференций, а также использованы в образовательном процессе для подготовки специалистов в области микроэлектроники и компьютерного зрения. Предполагается, что опыт и знания, полученные в ходе выполнения данной работы, будут способствовать дальнейшему развитию методов анализа и контроля качества литографических процессов и, в конечном итоге, совершенствованию технологий производства микроконтроллеров и других микроэлектронных устройств.




%% Начало содержательной части.
%% Так помечается начало обзора.
\startrelatedwork
\chapter{Описание предметной области}
В этой главе представлен обширный обзор литературы и исследований в области выделения контуров из изображений, полученных с помощью сканирующей электронной микроскопии (СЭМ). Среди метрологических инструментов в производстве полупроводников, сканирующие электронные микроскопы критического размера (CD-SEM) являются наиболее широко используемыми, особенно благодаря их высокому разрешению, низкой деструктивности и высокой пропускной способности. Размеры устройств на основе интегральных схем продолжают уменьшаться, согласно закону Мура и ITRS [1], размеры полупроводников непрерывно уменьшаются, и поэтому точная реализация узоров с правильными критическими размерами становится важной проблемой. Как следствие этой тенденции, не только критическая размерность (CD) самой минимальной характерной линии, но и качество линий и краев линий имеют важную роль. Шероховатость края линии (line edge roughness  LER) и шероховатость ширины линии (line width roughness LWR) линий резиста и соответствующих линий поликремния являются важными элементами управления процессом литографии и управления процессом травления. CD-сканиру ющая электронная микроскопия (СЭМ) широко используется в качестве инструмента для измерения фактического размера, формы и упоминутых измерениях. По мере того, как размеры устройств продолжают уменьшаться, становится все труднее соблюдать требования к шероховатости края линии и шероховатости ширины линии. 

Метрология контуров на изображениях CD-SEM стала необходимой для характеристики, моделирования и контроля передовых процессов литографии. В частности, точность модели OPC можно значительно улучшить, используя метрологию контуров. Однако, изображения, полученные с помощью SEM, часто содержат различные виды шумов, которые затрудняют корректное определение контуров объектов. Ниже основное внимание уделяется техникам и алгоритмам, которые были использованы для улучшения и выделения контуров на изображениях СЭМ, их преимуществам и ограничениям. 

Эта глава организована следующим образом: раздел 1.1 вводит основы изображений СЭМ; раздел 1.2 обсуждает методы предварительной обработки; раздел 1.3 охватывает методы выделения границ; раздел 1.4 представляет методы сегментации на основе регионов; раздел 1.5 рассматривает подходы, основанные на машинном обучении; и раздел 1.6 заключает главу.

\section{Основы СЭМ изображений}

Сканирующая электронная микроскопия - это метод изображения, который использует фокусированный пучок электронов для создания высокоразрешающих изображений поверхности образца. Главное преимущество СЭМ перед оптической микроскопией заключается в его способности создавать изображения с гораздо большей глубиной резкости и высоким разрешением, что критически важно для анализа сложных материалов и структур. В области материаловедения СЭМ стал неотъемлемым инструментом для характеристики и анализа различных материалов \cite{SEM}.

Несмотря на высокое разрешение и глубину резкости, предоставляемые СЭМ, получаемые изображения могут страдать от различных артефактов, таких как шум, неравномерное освещение и низкий контраст, что может затруднить процесс выделения контуров \cite{DIP}. Для преодоления этих ограничений в литературе было предложено множество техник, которые можно условно классифицировать на предварительную обработку, выделение границ, сегментацию на основе регионов и подходы, основанные на машинном обучении.

\section{Методы предварительной обработки}

Предварительная обработка изображений служит первым шагом в процессе выделения контуров из изображений, полученных с помощью СЭМ. Качество изображений СЭМ может значительно варьироваться в зависимости от свойств материала образца, параметров СЭМ и условий, при которых проводилось изображение. Таким образом, методы предварительной обработки критически важны для уменьшения шума, повышения контраста и обеспечения эффективного различения границ объектов и фона в последующих методах выделения контуров.

\subsection{Выравнивание гистограммы}

Выравнивание гистограммы - это распространенный метод, используемый для улучшения контраста изображений. В контексте изображений СЭМ этот метод работает путем эффективного распределения наиболее часто встречающихся значений интенсивности или "пиксельных значений" на изображении, тем самым улучшая общий контраст \cite{three}.

Важно отметить, что выравнивание гистограммы является глобальным методом, одинаково обрабатывающим все области изображения. Однако это может привести к чрезмерному усилению некоторых областей, вызывая насыщение. Чтобы преодолеть это ограничение, могут использоваться методы адаптивного выравнивания гистограммы, такие как адаптивное выравнивание гистограммы с ограничением контраста (CLAHE). CLAHE работает на малых областях изображения, называемых "плитками", а не на всем изображении. Это позволяет локально улучшить контраст, что может лучше учитывать вариации в изображениях СЭМ \cite{four}.

\subsection{Фильтрация}

Фильтрация изображений - это еще один важный этап предварительной обработки, используемый для уменьшения шума на изображениях СЭМ. Шум на изображениях СЭМ может иметь различное происхождение, включая электронный шум в устройстве СЭМ и случайные колебания в количестве обнаруженных электронов.

Различные фильтры могутиспользоваться для уменьшения шума на изображениях СЭМ, такие как гауссовы, медианные и фильтры анизотропной диффузии. Выбор фильтра зависит от типа и уровня шума, присутствующего на изображении. Например, гауссовы фильтры эффективны для уменьшения гауссового шума (то есть случайного шума с нормальным распределением). Медианные фильтры особенно полезны, когда шум имеет тип «соль и перец», где случайные пиксели устанавливаются на минимальные или максимальные значения. Фильтры анизотропной диффузии эффективны для уменьшения шума с сохранением информации о границах, что делает их особенно полезными при обработке изображений СЭМ \cite{five, six}.

Однако стоит отметить, что чрезмерная фильтрация может привести к потере важных деталей на изображении СЭМ. Таким образом, выбор фильтра и его параметров должен быть тщательно подобран на основе конкретных характеристик изображения СЭМ.

В заключение, методы предварительной обработки изображений являются существенными в выделении контуров изображений СЭМ. Путем повышения контраста и уменьшения шума эти методы готовят изображения СЭМ для более эффективного выделения контуров.

\section{Методы выделения границ}

Выделение границ является критически важным этапом в процессе извлечения контуров из изображений, полученных с помощью СЭМ. Границы объектов на изображении СЭМ представляют собой резкие изменения интенсивности, и методы выделения границ направлены на идентификацию этих мест изменения интенсивности. В литературе было предложено множество алгоритмов выделения границ, включая:

\subsection{Операторы градиента}

Операторы градиента, такие как операторы Собеля и Превитта, являются распространенными методами выделения границ. Они работают путем вычисления градиента интенсивности изображения, что позволяет выявить места резких изменений интенсивности \cite{DIP3}.

Оператор Собеля, например, использует два 3x3 ядра, которые применяются к исходному изображению для вычисления приближений горизонтальных и вертикальных производных. Затем эти два градиента объединяются для создания изображения границ \cite{DIP3}. Однако они чувствительни к шуму и могут не работать хорошо на изображениях СЭМ с низким контрастом \cite{eight}.

\subsection{Детектор границ Кэнни}

Метод Канни представляет собой многостадийный алгоритм выделения границ, который пытается оптимизировать различные аспекты выделения границ. Эти аспекты включают обнаружение всех истинных границ, локализацию границ в их истинных положениях и минимизацию отклика на границе. Метод Канни использует серию шагов, включая сглаживание, вычисление градиента, подавление не-максимумов и двойной порог, для достижения этих целей \cite{nine}.

Важно отметить, что, хотя эти методы выделения границ могут быть эффективными, они также могут выделять нежелательные границы из-за шума или других мелких деталей на изображении. Поэтому часто требуется дополнительная постобработка, включая морфологические операции и управление порогом, чтобы улучшить результаты выделения границ.

\subsection{Морфологические операции}

Морфологические операции, такие как дилатация, эрозия, открытие и закрытие, являются общепринятыми методами для улучшения результатов выделения границ. Эти методы могут использоваться для удаления мелких деталей (например, шума), заполнения небольших дыр в границах и разделения склеившихся границ \cite{ten}.

\subsection{Лапласиан Гаусса (LoG)}

Оператор LoG объединяет сглаживание по Гауссу с оператором Лапласа для обнаружения границ на изображениях \cite{TED}. Он менее чувствителен к шуму, чем оператор Собеля и детектор границ Кэнни, что делает его подходящим для шумных изображений СЭМ. Тем не менее, он требует больших вычислительных ресурсов и может не подходить для приложений в реальном времени.

\section{Техники сегментации на основе регионов}

Техники сегментации на основе регионов также применялись для выделения контуров из изображений СЭМ. Эти методы обычно работают путем группировки похожих пикселей на основе определенных критериев, таких как интенсивность или текстура.

\subsection{Пороговая обработка}

Пороговая обработка - это еще один важный метод, используемый для улучшения результатов выделения границ. При применении порогового значения к изображению границ, все пиксели с интенсивностью выше порога классифицируются как границы, а все остальные пиксели - как не границы. Выбор подходящего порога может быть сложной задачей и может зависеть от различных факторов, включая уровень шума на изображении и контраст между объектами и фоном \cite{eleven}. Несмотря на простоту, выбор подходящего порога может быть сложной задачей, особенно для изображений СЭМ с неравномерным освещением.

\subsection{Водораздел}

Преобразование водораздела - это мощная техника сегментации, основанная на концепции топологических водоразделов в полутоновом изображении \cite{twelve}. Он использовался для выделения контуров на изображениях СЭМ, особенно для изображений с перекрывающимися или соприкасающимися объектами \cite{effecSEM}. Однако он склонен к пересегментации, которую можно смягчить с помощью маркеров или техник предварительной обработки.

\subsection{Model based}

Название подсказывает что этот метод будет выделять контуры основываясь на модели, ее геометрическая форма, материя и т.д. Методы извлечения информации о критических размерах (CD) в сканирующих электронных микроскопах (СЭМ) в настоящее время основаны на яркости изображения. Яркость изображения сложно связана с размером, формой, ее материалом, геометрией паттерна поэтому был разработан метод извлечения критического размера CD из изображений СЭМ на основе модели. Анализ основан на понимании физических принципов, участвующих в формировании сигнала СЭМ\cite{modelbased}. Некоторые параметры, такие как напряжение луча и материалы, должны быть известны в качестве входных данных вместе с изображением СЭМ. Анализ изображений СЭМ на основе модели может значительно улучил точность измерений CD в СЭМ. В целом этот, поскольку они позволяют учесть физические принципы, лежащие в основе формирования сигнала СЭМ.


\section{Подходы на основе машинного обучения}

В последние годы машинное обучение, особенно глубокое обучение стало очень популярным при решении многих задач компютерного зрения, таких как шумоподавление, Super resolution, сегментация и востановление фотографий \cite{Tutorial_Survey}. Оно показало обнадеживающие результаты в выделении контуров из изображений СЭМ. Возможны два подхода как метод извлечения контура из СЭМ изображений, основанные на глубоком обучении. Первый подход использует глубокое обучение для уменьшения шума из CЭМ изображений и улучшения качества изображений, а затем только выделяют контур. Это похоже на метод с использованием усредняющий фильтр или фильтр Гаусса в качестве предварительной обработки. Второй подход использует глубокое обучение для непосредственного выделение контуров на входном изображении.

\subsection{Уменьшения шума из CЭМ изображений}

Авторы статьи \cite{UnsupervisedDenoise} предлагают использовать подход без учителя,
основанный на применении глубоких сверточных автоэнкодеров (Deep Convolutional Autoencoders, DCAE) для очистки изображений от шумов и повышения точности определения контуров, особенно для наноструктур. Автоэнкодеры являются типом искусственных нейронных сетей, способных выучивать эффективные представления данных без контролирующих меток. Сверточные автоэнкодеры используют сверточные слои вместо полносвязных слоев для сохранения пространственной структуры изображений и обеспечения инвариантности к трансляции. Помимо этого было предложено модель условного порождающей состязательной сети для улучшений качества СЭМ изображений \cite{cGAN}.


\subsection{Сети глубокого обучения для непосреднего извлечения контуров}

Глубокие сверточные сети DCNN широко используются для задач обработки изображений, включая выделение контуров. Они используют свертку для автоматического извлечения признаков из изображений и могут обучаться на больших наборах данных для обнаружения сложных паттернов. Но для хорошего выделения необходимо фотографии высокого качества\cite{effecSEMcontour}.

\subsection{Сети на основе внимания}

Сети на основе внимания - это новейший подход в области машинного обучения, который использует механизм внимания для определения важных областей на изображении во время обучения. Они показали впечатляющие результаты в задачах обработки изображений, включая выделение контуров из изображений СЭМ [16].

%% Так помечается конец обзора.
\finishrelatedwork

\chapterconclusion

В ходе обзора современной литературы были изучены и проанализированы ключевые методы и подходы к выделению контуров из изображений, полученных с помощью сканирующего электронного микроскопа (СЭМ). Было обнаружено, что методы варьируются от применения простых техник предварительной обработки и выделения границ до более сложных и инновационных подходов, применение машинного обучения. Но несмотря на все, результаты не удовлетворяют.

Данная модель разрабатывается для анализа критических размеров (CD) СЭМ изображений микроконтроллеров. В массовом производстве при большем количестве данных с возможными искожениями необходимо более точная модель.

Изучение литературы позволило более глубоко понять текущее состояние исследований в области выделения контуров из изображений СЭМ и вследушем главе представлено свое направление для решения.



\chapter{ПРИМЕНЯЕМЫЙ МЕТОД}


Преди исследованием и разработкой собственного алгоритма был выполнен обзор существующих готовых решений в области выделения границ на изображениях. И тестировались методы на СЭМ изображениях.

В контексте нашего исследования обзор готовых решений был очень важным этапом. Он позволил ознакомиться с уже существующими подходами, сравнить их эффективность и определить возможность применения в контексте нашей задачи. Было рассмотрено множество методов и алгоритмов, ориентированных на выделение границ на изображениях. В процессе анализа и оценки были учтены такие аспекты, как скорость работы, точность, устойчивость к шумам, возможность масштабирования.

Среди рассмотренных нами алгоритмов были такие методы, как Sobel, Canny, Scharr и Laplacian, которые изначально используются в области компьютерного зрения для выделения границ на изображениях. Эти методы основаны на использовании производных изображений. После премения этих методов самый гланый недостаток был не устойчивость к шумам. На шумных фотографиях выделялились много ложно положительных контуров.

Также были испытаны более современные подходы, основанные на глубоком обучении, такие как U-Net, Mask R-CNN, и Pix2Pix. Они продемонстрировали впечатляющую точность, но также требуют большего количества ресурсов и времени для обучения и работы.

Тестирование методов на СЭМ (сканирующей электронной микроскопии) изображениях дало нам возможность оценить их эффективность в специфической области применения. В связи с особенностями СЭМ изображений, как например, шум и сложные текстуры, выделение границ является непростой задачей.

Собранные данные и результаты тестирования позволили нам сформулировать требования к новому алгоритму, а также избежать возможных проблем, связанных с недостатками уже существующих решений. Этот обзор и исследование подготовило нас к разработке собственного алгоритма, который бы удовлетворял всем необходимым требованиям и был оптимизирован для работы с СЭМ изображениями.

\section{Анализ применения готовых решений}

Каждое из примененных решений было протестировано на наборе изображений СЭМ. Было выяснено, что хотя многие из них успешно справляются с задачей на определенных типах изображений, ни одно из них не обладает универсальностью для всех видов изображений СЭМ. В частности, многие алгоритмы испытывают трудности при работе с изображениями с низким контрастом или с высоким уровнем шума.

\section{Применимость готовых решений к задаче выделения границ}

В результате анализа было выявлено, что некоторые аспекты готовых решений могут быть полезными для решения нашей задачи. В частности, методы PDC используя кастомный фильтр в свертке предсказывает хорошие фото на шумных изображениях. А LDC модель способна адаптироваться к различным задачам обнаружения границ, обучаясь на различных типах данных и настроек. Однако для достижения наилучших результатов необходимо дополнительное развитие и адаптация этих методов.

\section{Разработка собственного решения на основе анализа готовых}

Основываясь на полученных данных, было принято решение разработать собственный алгоритм выделения границ. Данный алгоритм комбинирует наилучшие аспекты готовых решений с учетом специфики изображений СЭМ.

В нашем методе мы реализуем совместное использование LDC и PDN, двух высокоэффективных подходов в области обработки изображений. Оба метода обнаружения границ основаны на слияния разномасштабных признаков. Сверточные нейронные сети анализируют свойства целевого объекта через последовательную абстракцию на каждом слое, где центральной идеей является поле восприятия. Сети более высокого слоя имеют большее поле восприятия и сильную способность описывать семантическую информацию, в то время как сети нижнего уровня, хоть и имеют меньшее поле восприятия, обладают высокой способностью отражать детализированную геометрическую информацию. Именно поэтому объединение признаков разных масштабов становится ключевым методом для улучшения эффективности обнаружения границ.

Специфика архитектуры LDC что она может быть использована для любой задачи обнаружения границ с целью создания тонких карт границ, видимых для человеческого глаза, без предварительного обучения или процесса тонкой настройки. LDC является более легкой версией модели DexiNed. Эта особенность дает возможность значительно снизить вычислительную сложность и увеличить скорость обработки изображений. С другой стороны, применение LDC не ведет к значительному ухудшению качества и точности обнаружения объектов на изображениях. Вдохновленные сетями HED и Xception (Chollet, 2017), Сория и его коллеги (Poma et al., 2020) предложили DexiNed, детектор границ, основанный на глубоком обучении. Эта сеть  DexiNed можно рассматривать как две подсети: экстремально плотная начальная сеть (Dexi) и блок апсемплинга (UB). Эта сеть состоит из шести кодеров, и каждый основной блок выдает соответствующее отображение признаков для генерации промежуточных карт границ с использованием блока апсемплинга. Все карты границ, сгенерированные блоком апсемплинга, будут соединены в конце сети, чтобы предоставить фильтры для обучения и создания совмещенных карт границ. Одним из ключевых компонентов уточнения границ является блок апсемплинга, который состоит в основном из сверточных и деконволюционных слоев. 

Также в нашем методе мы интегрируем подход PDN, основанный на определении границ через разницу в пикселях. PiDiNet использует новую свертку разницы пикселей (Pixel difference Convolution: PDC), чтобы интегрировать традиционный оператор обнаружения границ в популярную операцию свертки в современных CNN, что повышает эффективность задачи обнаружения границ. PDC может легко захватить информацию о градиенте изображения, способствующую обнаружению границ, сохраняя при этом мощную способность глубоких CNN извлекать информацию с семантическим значением. Кроме того, PDC не зависит от информации о границах ручного детектора, но напрямую интегрирует процесс извлечения информации о градиенте в операцию свертки, что обеспечивает лучшую устойчивость и точность обнаружения границ. Таким образом, сеть PiDiNet все еще может эффективно, надежно и точно реализовывать обнаружение границ, даже когда она занимает небольшое количество памяти. Использование разницы пикселей позволяет нам определить границы объектов с большой точностью, даже при обработке изображений с высоким разрешением.

Комбинирование этих двух подходов в одной системе позволяет нам получить и преимущества вычислительной эффективности LDC, и точность обнаружения границ PDN. В результате получается уникальная система, способная быстро и точно определить границы объектов на изображении, что делает наш подход подходящим для широкого спектра приложений.

\section{LDC: Lightweight Dense CNN for Edge Detection}

Статья представляет новую архитектуру - Легкую Плотную Сверточную нейронную сеть для обнаружения границ (LDC), которая направлена на улучшение ранее разработанных архитектур DexiNed и CATS, внося изменения, которые делают ее значительно более легкой в отношении параметров, не ухудшая качества обнаружения границ.

Архитектура LDC включает только четыре блока из модели DexiNed, которая изначально состоит из шести блоков. Эта корректировка сделана для достижения легкой модели без ущерба для производительности модели.

Кроме того, LDC использует фильтры меньшего размера по сравнению с DexiNed. Это снижает количество параметров и дополнительно способствует созданию легкой модели.

В дополнение к этому, LDC включает блок CoFusion (Context-aware Fusion block), вдохновленный моделью CATS. Этот блок объединяет четыре промежуточных прогноза карты границ, чтобы получить окончательный результат. CoFusion в LDC - это упрощенная версия того, что есть в CATS, использующая меньше сверточных слоев и групп нормализации, и меньший размер ядра, что дополнительно способствует созданию легкой модели.

Для сохранения создания промежуточных карт границ, LDC сохраняет конфигурацию USNet из DexiNed. Он также изменяет функцию потерь из CATS для обучения.

Что касается функции потерь, используется модифицированная версия функции потерь CATS, называемая CATSloss2. Эта функция объединяет потери отслеживания (cross-entropy), потери трассировки границ и потери подавления текстуры. Каждый тип потерь служит определенной цели в улучшении качества обнаружения границ, включая лучшее отслеживание границ, улучшенное идентифицирование границ границ и более эффективное подавление текстур не границ. Использование этих потерь помогает модели улучшить точность результатов обнаружения границ.

В целом, предлагаемая архитектура LDC, похоже, предлагает значительное продвижение в области обнаружения границ, сокращая вычислительные требования без значительного ущерба для производительности. Однако, как и при любом подходе, было бы важно оценить его практическую работу на ряде наборов данных и задач обнаружения границ, чтобы подтвердить его преимущества и выявить любые потенциальные слабые стороны или ограничения.

\section{Pixel Difference Networks for Efficient Edge Detection}

Основная идея подхода, представленного здесь, - это Pixel Difference Convolution (PDC), которая предлагает усовершенствование традиционного метода свертки в глубоком обучении, специально адаптированное для задач детекции контуров. Вместо обычного подхода, где исходные пиксели в локальной карте признаков обрабатываются с использованием сверточных ядер, PDC заменяет эти пиксели на их разности, вычисляемые в ходе сверточных операций. Формулы для обычной свертки и PDC можно записать следующим образом:
\begin{equation} 
    \begin{split}
        y = f(x, \theta) = \sum_{i=1}^{k×k} w_i * x_i, (\text{обычная свертка}) \\
        y = f(\deltax, \theta) = \sum_{(x_i, x_i')\in P} w_i * (x_i - x_i'),(\text{PDC})
    \end{split}
\end{equation}

В рамках этого подхода вводятся три новых вида свертки: Central Pixel Difference Convolution (CPDC), Angular Pixel Difference Convolution (APDC) и Radial Pixel Difference Convolution (RPDC). Эти свертки построены на основе методики расширенных дескрипторов Local Binary Pattern (ELBP), кодирующих отношения между пикселями, взятыми из различных направлений - угловых и радиальных. Подобный подход усиливает представительность извлекаемых признаков и значительно улучшает результаты в различных задачах компьютерного зрения, таких как классификация текстур и распознавание лиц.

PDC, как было описано выше, дает возможность извлекать более сложные и информативные признаки по сравнению с обычной сверткой. CPDC, APDC и RPDC каждый по-своему обрабатывают входные данные, извлекая разные типы информации, что делает модель более универсальной и устойчивой к различным условиям. Благодаря этому, модель становится способной более точно и эффективно определить границы объектов, даже в условиях сложных или многообразных изображений.

\begin{figure}[!h]
\caption{Пример рисунка}\label{fig1}
\centering
\includegraphics[width=\textwidth]{img/pixel.png}
\end{figure}

Итак, мы видим, что PDC, сочетая различные варианты свертки, обеспечивает новые возможности для анализа и обработки изображений. Такой подход способствует более глубокому пониманию контента изображения и может значительно повысить точность и эффективность систем компьютерного зрения, расширяя горизонты применимости глубокого обучения в этой области.


\section{Новая модель}

В этом разделе будет подробно описано наш новаторский подход к проектированию новой архитектуры, в которой за основу будет использовать архитектуру высшеупоменатой (LDC) модели и применять особую форму свертки, называемую сверткой разности пикселей (PDC), в отличие от обычного метода свертки.

\subsection{Концептуализация подхода}

Основная цель предлагаемого подхода - построить архитектуру, которая может использовать мощный потенциал LDC в сочетании с PDC. Целью является улучшение процесса извлечения признаков и, в конечном итоге, повышение эффективности и производительности предлагаемой модели.

Основа этого исследования начинается с понимания того, что традиционные методы свертки используют одни и те же фильтры или ядра для каждого пикселя, игнорируя изменчивость содержимого изображений. В этом отношении мы считаем, что PDC является потенциальной альтернативой обычной свертке, поскольку она применяет более адаптивный подход. Она учитывает разницу между значениями пикселей и соответственно адаптирует ядро. Использование этой необычной техники свертки в сочетании с LDC направлено на улучшение представления признаков и повышение способности обучения модели.


\subsection{Architecture Design}

Архитектура LDC (Lightweight Dense CNN) используется в нашей новой модели для обнаружения границ и представляет собой более легкую версию архитектуры DexiNed. LDC разработана таким образом, чтобы обучение могло проходить полностью без необходимости инициализации весов из предварительно обученных моделей обнаружения объектов, что часто требуется в большинстве глубоких моделей обнаружения границ.

Исходя из наблюдений[40], что информация о границах, вычисленная на поверхностных слоях, часто теряется на более глубоких слоях, было решено разработать архитектуру, аналогичную Xception[41], но с двумя параллельными skip-connection, которые сохраняют всю информацию о границах, вычисленную на разных слоях.

Архитектура DexiNed можно рассматривать как совокупность двух подсетей: (Dexi) и сети для восстановления размера (USNet). Dexi получает на вход изображение и обрабатывает его в разных блоках, после чего на выходе получается карты признаков, которые в свою очередь передаются в USNet для создания промежуточных карт границ. Эти промежуточные карты затем объединяются в стек с использованием настроенных фильтров. В конечном итоге, все эти признаки сливаются для создания единственной карты границ.

В общем, подход LDC направлен на улучшение обнаружения границ, сохраняя информацию о границах.

\begin{figure}[!h]
\caption{Архитектура DexiNed}\label{fig3}
\centering
\includegraphics[width=17cm,height=14cm]{img/dexi_1.png}
\end{figure}

\textbf{Dexi} Архитектура DexiNed содержит шесть блоков, которые работают аналогично кодировщику. Каждый блок представляет собой набор более мелких подблоков с группой сверточных слоев. Связи пропускания связывают блоки, а также их подблоки (изображены светло-серыми и синими прямоугольниками на рис. 3). Карты признаков, генерируемые в каждом из блоков, передаются в отдельную сеть USNet для создания промежуточных карт границ. Эти промежуточные карты границ объединяются в стек наученных фильтров. В конце концов, эти признаки сливаются для создания единой карты границ.

Каждый подблок (синие прямоугольники на рис. 3) состоит из двух сверточных слоев (количество ядер указано справа от синих прямоугольников). Все ядра имеют размер 3 × 3. В самом первом блоке свертки выполняются со смещением 2. За каждым сверточным слоем следуют нормализация по батчам и функция активации (ReLU). Начиная с блока 3 (светло-серые прямоугольники), последний сверточный слой последнего подблока не содержит функции ReLU. Прямоугольники в красной рамке - это операторы максимального пулинга с размером ядра 3 × 3 и шагом 2.

Для решения высше упоменутой проблемы о утечки информации о границах, начиная с третьего блока, после каждого подблока усредняется с параллельными skip-connection. После операции максимального пулинга skip-connection усредняют выходные данные соединенных подблоков, до суммирования с первым skip-connection (на верней стороне). 
  
\textbf{USNet} Сеть для восстановления размера, или USNet, представляет собой условный стек из двух блоков. Каждый блок включает в себя сверточный и деконволюционный слои, которые на каждом этапе увеличивают размер карты признаков. Второй блок активируется исключительно для изменения масштаба входных карт признаков, полученных из сети Dexi. Этот блок продолжает повторяться, пока размер карты признаков не достигнет в два раза большего размера целевой карты границ (GT). Как только это условие выполнено, карта признаков передается в первый блок. Блок-1 обрабатывает входные данные с использованием сверточного ядра размером 1x1, за которым следует функция активации ReLU. Затем выполняется обратная свертка (деконволюция) с ядром размером s × s, где s - это уровень масштаба входной карты признаков. После последнего деконволюционного слоя в блоке-1, карта признаков достигает размера целевой карты границ (GT). При этом, последний сверточный слой в этом блоке не содержит функции активации.


Исходя из предыдущего контекста, было сказано, что архитектура LDC стала основой, которая включает две подсети: Dexi и USNet. Архитектура LDC в своей сети Dexi сократил блоки с шести до четырех, где третий и четвертый блоки связаны двумя типами skip-connections. После карт границ подаются в USNet. Суммируя идею USNet представляет собой условную сверточную нейронную сеть (CNN), задача которой заключается в увеличении масштаба и преобразовании карт признаков в карты границ с тем же размером, что и входное изображение подсети Dexi.  Кажый блок в сети LDC генерирует четыре промежуточных прогноза карт границ. В отличии от оригинальной модели DexiNed в LDC стратегия совмешения карт границ отличается. Стратегия слияния карт границ была взаимственна из CATS [9], называется блоком контекстно-зависимого слияния или просто CoFusion.

В текущей работе, с акцентом на сегментацию СЭМ изображений, предлагаются следующие модификации в архитектуре LDC:


\begin{itemize}
    \item Обычная свертка заменяется на свертку разности пикселей (PDC).
    \item Добавить фильтры шумоподавления.
\end{itemize}

\begin{figure}[!h]
\caption{Новая архитектура}\label{fig1}
\centering
\includegraphics[width=\textwidth]{img/new_model.png}
\end{figure}

\section{Обучение и тестирование модели}

Обучение модели проводится с использованием стандартных техник глубокого обучения. Мы используем сеть градиентного спуска для минимизации ошибки между предсказанными и реальными границами на обучающем наборе данных. В процессе обучения веса сети настраиваются таким образом, чтобы оптимизировать эту ошибку.

\subsection{Функция потерь}

Для обучения модели мы используем комбинацию функции потерь, которая состоит из трех пфункций: потери трассировки (кросс-энтропии) $l_t$, потери трассировки границ $l_{bt}$ и потери подавления текстуры $l_{txs}$. Таким образом, результирующая функция вычисляется следующим образом:

\begin{equation} 
    l = l_t + \alpha_{bt} × l_{bt} + \alpha_{txs} × l_{txs}
\end{equation}

где $\alpha_{bt}$ — вес для регуляризации потерь при отслеживании границ, а
$\alpha_{txs}$ предназначен для потери подавления текстуры для каждого предсказания LDC.

\begin{itemize}
    \item bdcnloss2 - $l_t$: Это взвешенная потеря бинарной кросс-энтропии. Взвешивание выполняется для управления дисбалансом между пикселями границ и не-границ в изображении. Пиксели границы получают вес 1.0 * num negative / (num positive + num negative), а пиксели не-границ получают вес 1.1 * num positive / (num positive + num negative). Этот вес затем используется в вычислении потери бинарной кросс-энтропии.
    \item bdrloss - $l_{bt}$: Эта потеря, известная как потеря прослеживания границы, разработана для обработки путающих пикселей. Она вычисляет карту softmax предсказания границы и использует ее для вычисления потери кросс-энтропии. Предсказание границы делается путем свертки метки и предсказания с фильтром, а потеря равна нулю для пикселей, не являющихся границей.
    \item textureloss - $l_{txs}$: Эта потеря, известная как потеря подавления текстуры, разработана для сглаживания областей текстуры. Она вычисляет сумму предсказания путем свертки предсказания с фильтром, затем вычисляет маску с использованием суммы меток. Маска используется для вычисления потери кросс-энтропии, при этом потеря для пикселей границы равна нулю.
\end{itemize}








\subsection{Оптимизатор}

Мы используем оптимизатор Adam для обучения нашей модели. Оптимизатор Adam сочетает в себе преимущества двух других методов оптимизации градиентного спуска, RMSProp и AdaGrad, обеспечивая эффективное и быстрое обучение.

\chapterconclusion

В заключении можно сказать, что применение готовых решений дало ценный опыт и понимание проблемы, что в дальнейшем помогло в разработке собственного эффективного алгоритма выделения границ.



\chapter{ЭКСПЕРИМЕНТЫ И РЕЗУЛЬТАТЫ}

Изначально мы поставили нашу модель LDC на обучение с дефолтными параметрами на нашем наборе данных SEM, состоящем из 400 примеров. Однако начальные показатели эффективности модели указывали на возможность улучшения. Поэтому была реализована донастройка (fine-tuning) как следующий логический шаг. Чтобы использовать преимущества переноса обучения, была загружена предварительно обученная модель LDC, изначально обученная на наборе данных BSDS500. Переносное обучение позволяет нам использовать модель, которая уже изучила закономерности из другой, но со связанной проблемой, что делает ее особенно полезной при работе с небольшими наборами данных. 

Загрузка предварительно обученной модели и ее дальнейшая донастройка (fine-tuning) под специфический набор данных SEM (Scanning Electron Microscope) является продуктивным подходом к решению задачи. Визуально впечатляющие результаты, полученные с использованием предобученной модели на наборе данных SEM, подтверждают целесообразность такого подхода и указывают на потенциал для улучшения. Fine-tuning предварительно обученной модели позволяет задействовать уже выученные моделью признаки и приспособить их для специфики новых данных. В нашем случае, это может помочь лучше справиться с выделением краев на изображениях SEM.

Процесс донастройка (fine-tuning) начался с корректировки скорости обучения (lr) модели, которая сначала была уменьшена, чтобы предотвратить большие обновления весов модели и сохранить полезные особенности, изученные на наборе данных BSDS500. Постепенно, как модель начинала адаптироваться к набору данных SEM, скорость обучения постепенно увеличивалась, чтобы позволить более значительные обновления. Важно учитывать, что при слишком большом скорости обучения может привести к тому, что модель "забудет" предобученные признаки, в то время как слишком маленькая может привести к медленной сходимости.

Данный эксперимент привел к улучшению производительности модели LDC на наборе данных SEM, хотя и не идеально. С новым набором оптимизированных гиперпараметров модель показала лучшую точность, полноту, точность и F1-оценку, чем раньше. Однако некоторые сложные примеры в наборе данных SEM по-прежнему были неправильно классифицированы, что указывает на возможность дальнейших улучшений. 

Следующий этап улучшения результатов включал применение ансамблевого обучения для нейронных сетей. Сначала мы обучили модель LDC с различными параметрами, а затем применили ансамблевый подход. F1-оценка улучшилась, но все еще была недостаточной для эффективного выделения краев. На следующем шаге мы использовали ансамблевый подход для сочетания моделей LDC и PiDiNet. Этот подход демонстрировал схожие результаты. Вследствие случайности данных и обучающихся параметров модель иногда показывала немного лучшие результаты, но в общем и целом ее эффективность не улучшилась.

Одной из возможных причин неоптимальных результатов может быть высокий уровень внутреннего шума и сложности в SEM-изображениях, что затрудняет распознавание образов. Кроме того, относительно меньший размер набора данных SEM (400 примеров, эта самое болшое ограничение нашей задачи, но возможно в будушем будут пополнения данных) также может способствовать трудностям модели в выявлении тонких деталей, присутствующих в SEM-изображениях.

%Кроме того, были отрегулированы конкретные гиперпараметры модели LDC, включая %решатель, усадку и толерантность. Для этого использовалась комбинация ручной %настройки и поиска по сетке. Эти методы обеспечили систематический и всесторонний %поиск по пространству гиперпараметров, чтобы определить оптимальный набор, который %обеспечит лучшую производительность.

Несмотря на то что производительность модели LDC улучшилась благодаря тонкой настройке, это также выявило ограничения модели в работе со сложностью SEM-изображений. После чего во время тестирования модели PiDiNet было замеченно оно более робастно удаляет лишний шум из тестовых СЭМ изображений. На основе этих наблюдений сгенерировалась идея совместить две модели LDC и PiDiNet. Совмещение архитектуры LDC и новой свертки PiDiNet было нацелено на создание модели, которая могла бы воспользоваться сильными сторонами обеих. Для этого, мы скопировали структуру модели LDC и внедрили идею свертки из PiDiNet, которая способсвует хорошему извлечению признаков. Этот новый подход имеет потенциал преодолеть проблемы, которые были замечены при обучении модели LDC на нашем наборе данных SEM. Более подробно про архитектуру было рассказанно во второй главе.

Сперва новую модель обучили на тестовых данных без аугментации, из-за маленького набора данных результирующая модель показывала результаты не лучше других моделей. Следуюшем шагом было аугментация данных. Но все равно резултат значительно не улучшился. После этого было решено обучить модель на BSDS500 а потом применить применить fine-tunning, т.е. загрузить уже предобученную модель и уже обучить на своих СЭМ изображениях.




3.1. Оценка модели

Для оценки результативности модели мы использовали метрику F1-score, которая представляет собой гармоническое среднее между точностью и полнотой. Также была использована метрика Intersection over Union (IoU), которая позволяет оценить степень перекрытия между предсказанными и истинными контурами.

После тонкой настройки модели на наших SEM изображениях, мы обнаружили заметное улучшение в ее производительности. Финальная модель показала улучшение в F1-оценке и метрике IoU по сравнению с исходной моделью LDC и PiDiNet.

Важно отметить, что эти улучшения были достигнуты несмотря на ограниченность нашего набора данных SEM. Мы считаем, что дальнейшее улучшение могло бы быть достигнуто с использованием большего количества данных для обучения.

3.2. Заключение

На основе проведенных экспериментов и полученных результатов, мы пришли к выводу, что комбинированная модель, включающая элементы LDC и PiDiNet, обеспечивает лучшие результаты для выделения контуров в SEM изображениях. Мы также выявили, что подход fine-tuning с использованием большего набора данных, таких как BSDS500, и последующим обучением на SEM изображениях дает лучшие результаты.

Однако следует отметить, что в этой работе были использованы только 400 примеров SEM изображений, что может быть ограничением для обучения глубоких нейронных сетей. В будущем, при доступности большего количества данных, ожидается дальнейшее улучшение результатов.

Все вместе, это исследование представляет собой важный шаг в направлении более точного выделения контуров на SEM изображениях, что, в свою очередь, может повысить точность и надежность метрологии в полупроводниковой промышленности.

\section{Заключение}

В этой главе был представлен наш подход к обнаружению границ, который объединяет легковесную и вычислительно эффективную архитектуру LDC с подходом PDN к определению границ через разницу в пикселях. Были рассмотрены основные аспекты нашего подхода, включая структуру модели, процесс обучения и методы оценки её эффективности.

Несмотря на то что производительность модели LDC улучшилась благодаря тонкой настройке, это также выявило ограничения модели в работе со сложностью SEM-изображений. Выводы из этого эксперимента указывают на необходимость более сложных моделей или методов ансамбля, которые могут потенциально дать лучшие результаты.

В будущих работах мы предлагаем исследовать использование более сложных моделей, таких как сверточные нейронные сети, или методы ансамбля, которые могут эффективно выявлять тонкие детали, присутствующие в SEM-изображениях. Кроме того, будут рассмотрены методы для увеличения набора данных SEM и дальнейшие методы устранения шума, чтобы улучшить способность модели к обучению.


\subsection{Преимущества подхода}

Преимущества нашего подхода включают его эффективность и легковесность. Благодаря комбинированию LDC и PDN, наш метод может эффективно обнаруживать границы на изображениях, используя при этом относительно небольшое количество вычислительных ресурсов. Это делает его подходящим для использования в сценариях, где доступны только ограниченные вычислительные ресурсы, таких как мобильные устройства или встроенные системы.


\subsection{Потенциальные ограничения и направления для дальнейшего исследования}

Несмотря на преимущества нашего подхода, он также имеет некоторые ограничения. Одно из них - это возможное наличие ложных срабатываний или пропусков при определении границ из-за вариаций в качестве исходного изображения. Для решения этой проблемы, возможным направлением для дальнейшего исследования может быть включение дополнительных процедур предварительной обработки или использование более сложных моделей для обнаружения границ.

В заключение, наш подход представляет собой эффективный и легковесный метод обнаружения границ на изображениях. С помощью комбинирования техник из LDC и PDN, он обеспечивает превосходное обнаружение границ с минимальным использованием вычислительных ресурсов. Будущие исследования могут расширить этот подход, чтобы справиться с его ограничениями и улучшить его эффективность и точность.


%% Макрос для заключения. Совместим со старым стилевиком.
\startconclusionpage

В данном разделе размещается заключение.

\printmainbibliography

%% После этой команды chapter будет генерировать приложения, нумерованные русскими буквами.
%% \startappendices из старого стилевика будет делать то же самое
\appendix

                

\end{document}
